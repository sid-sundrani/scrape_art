{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from urllib.parse import urljoin\n",
    "from selenium import webdriver\n",
    "import os\n",
    "from collections import deque\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "import time\n",
    "import regex as re\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_art_urls_from_genre(genre_art_url):\n",
    "    \"\"\"\n",
    "    input: url of genre page that contains all its art titles \n",
    "    output: list of beautiful soup objects containing all art titles on the page  \n",
    "    \"\"\"\n",
    "    genre_soup = BeautifulSoup(genre_art_url, 'html.parser')\n",
    "    title_blocks = genre_soup.find_all('div', \"title-block\")\n",
    "    print(f'Number of art titles {len(title_blocks)}')\n",
    "    return title_blocks \n",
    "\n",
    "\n",
    "def go_to_art_page(website_url, title_block):\n",
    "    \"\"\"\n",
    "    input: block soup object containing details of art details \n",
    "    output: return html art page   \n",
    "    \"\"\"\n",
    "    art_address =  title_block.find('a', 'artwork-name ng-binding')\n",
    "    art_url = urljoin(website_url, art_address['href'])\n",
    "    art_page_html = requests.get(art_url).text\n",
    "\n",
    "    return art_page_html\n",
    "\n",
    "def clean_string(string):\n",
    "    # remove filename illegal chars\n",
    "    string = re.sub(\"[?():/]\",\"\",string)\n",
    "    \n",
    "    return string.strip().replace('\"', '').lower()\n",
    "\n",
    "    \n",
    "def get_art_details_from_page(art_page_html):\n",
    "    \"\"\"\n",
    "    input: soup object of art page \n",
    "    output: dictionary of details of art from page \n",
    "    \"\"\"\n",
    "    art_page_soup = BeautifulSoup(art_page_html, 'html.parser')\n",
    "    # access block that contains art metadata \n",
    "    art_article = art_page_soup.find_all('article')[0]\n",
    "    art_title_name = art_article.h3.text\n",
    "    art_author_name = art_article.h5.text\n",
    "\n",
    "    style_genre_container = art_article.find_all('li', 'dictionary-values')\n",
    "    art_style = style_genre_container[0]\n",
    "    assert 'style' in art_style.s.text.lower()\n",
    "\n",
    "    # art style \n",
    "    art_style_name = art_style.find('a').text\n",
    "    \n",
    "    # get all images on art page \n",
    "    image_soups = art_page_soup.find_all('img')\n",
    "\n",
    "    art_image_url = image_soups[0]['src']\n",
    "\n",
    "    return {'title': clean_string(art_title_name),\n",
    "            'artist': clean_string(art_author_name),\n",
    "            'style': clean_string(art_style_name), \n",
    "            'image_url': art_image_url}\n",
    "\n",
    "\n",
    "def scroll_down_to_bottom(driver):\n",
    "    \"\"\"\n",
    "    scroll down to load more art \n",
    "    \"\"\"\n",
    "    def load_more(driver):\n",
    "        time.sleep(2)\n",
    "        driver.find_element_by_class_name('load-more-phrase').click()\n",
    "        \n",
    "    def close_accidental_zoom(driver):\n",
    "        time.sleep(2)\n",
    "        driver.find_element_by_class_name('sueprsized-navigation-close').click()\n",
    "\n",
    "    for i in range(500):\n",
    "        try: \n",
    "            load_more(driver)\n",
    "        except:\n",
    "            try:\n",
    "                close_accidental_zoom(driver)\n",
    "            except:\n",
    "                try: \n",
    "                    load_more(driver)\n",
    "                except:\n",
    "                    try:\n",
    "                        close_accidental_zoom(driver)\n",
    "                    except:\n",
    "                        return 0 \n",
    "                \n",
    "# destination \n",
    "write_folder = Path(os.path.join(os.getcwd(), 'crawl_data'))\n",
    "\n",
    "if not write_folder.exists():\n",
    "    write_folder.mkdir()\n",
    "        \n",
    "\n",
    "# crawl source \n",
    "website_url = 'https://www.wikiart.org/'\n",
    "\n",
    "# go to genre page \n",
    "website_genre_page = urljoin(website_url, 'en/paintings-by-genre')\n",
    "response = requests.get(website_genre_page)\n",
    "genre_page_soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "# get links of each genre \n",
    "genres_container = genre_page_soup.find_all('ul', 'dictionaries-list')[0] \n",
    "\n",
    "# try out \n",
    "genres_container = genre_page_soup.find('ul', 'dictionaries-list')\n",
    "genre_link_containers = genres_container.find_all('a')\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "driver.minimize_window()\n",
    "\n",
    "for genre_link_container in genre_link_containers:\n",
    "    extension = genre_link_container['href']\n",
    "    genre_name = genre_link_container.text\n",
    "    genre_name = ''.join(filter(str.isalpha, genre_name))\n",
    "    \n",
    "    genre_url = urljoin(website_url, extension)\n",
    "\n",
    "    # go to the genre page that contains all its art\n",
    "    driver.get(genre_url)\n",
    "\n",
    "    # scroll to bottom \n",
    "    status = scroll_down_to_bottom(driver)\n",
    "        \n",
    "    genre_art_url = driver.page_source\n",
    "    art_title_blocks = get_art_urls_from_genre(genre_art_url)\n",
    "\n",
    "    csv_filepath = write_folder/f'{genre_name}.csv'\n",
    "    \n",
    "    for i, art_title_block in enumerate(art_title_blocks):\n",
    "        art_page = go_to_art_page(website_url, art_title_block)\n",
    "        \n",
    "        art_metadata = get_art_details_from_page(art_page)\n",
    "        art_metadata['genre'] = genre_name\n",
    "        \n",
    "        url = art_metadata['image_url']\n",
    "        \n",
    "        response = requests.get(url, stream=True)\n",
    "        ext = response.headers['content-type'].split('/')[-1]\n",
    "        \n",
    "        write_sub_folder = write_folder/f\"{art_metadata['genre']}\"\n",
    "        \n",
    "        if not write_sub_folder.exists():\n",
    "            write_sub_folder.mkdir()\n",
    "        \n",
    "        fname = art_metadata['title'] + ('.' + ext)\n",
    "        image_path = write_sub_folder/fname\n",
    "        image_path = image_path.relative_to(os.getcwd())\n",
    "        \n",
    "        with open(image_path, 'wb') as f:\n",
    "            f.write(response.content)\n",
    "\n",
    "        if not csv_filepath.exists():\n",
    "            with open(csv_filepath, 'w') as f:\n",
    "                f.writelines('artist,title,style,image_path\\n')\n",
    "                f.writelines(\n",
    "                    f\"{art_metadata['artist']},{art_metadata['title']},{art_metadata['style']},{str(image_path)}\\n\"\n",
    "                )\n",
    "        else: \n",
    "            with open(csv_filepath, 'a') as f:\n",
    "                f.writelines(\n",
    "                    f\"{art_metadata['artist']},{art_metadata['title']},{art_metadata['style']},{str(image_path)}\\n\"\n",
    "                )\n",
    "   \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# writing csv test \n",
    "\n",
    "import pandas as pd \n",
    "\n",
    "with open('file.csv', 'w') as f:\n",
    "    f.writelines('col1, col2\\n')\n",
    "    f.writelines('d1,d2\\n')\n",
    "with open('file.csv', 'a') as f:\n",
    "    f.writelines('d1,d2\\n')\n",
    "\n",
    "pd.read_csv('file.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gym",
   "language": "python",
   "name": "gym"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
